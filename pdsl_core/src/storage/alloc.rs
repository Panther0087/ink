use crate::{
	storage::{
		self,
		Key,
	},
	byte_utils,
};

use parity_codec_derive::{Encode, Decode};

/// Types implementing this trait are storage allocators.
pub trait Allocator {
	/// Allocates a storage area.
	///
	/// The returned key denotes a storage region that fits for at
	/// least the given number of cells.
	fn alloc(&mut self, size: u32) -> Key;

	/// Deallocates a storage area.
	///
	/// The given storage region must have been allocated by this
	/// allocator before.
	fn dealloc(&mut self, key: Key);
}

/// A specialized allocator for the storage.
///
/// It allows for two types of allocations:
///
/// 1. Single cell allocation
/// 2. Cell chunk allocation
///
/// Allocating and deallocating are always O(1) operations.
#[derive(Debug, Encode, Decode)]
pub struct CellChunkAlloc {
	/// Allocator stash for single cells.
	cells: storage::Stash<()>,
	/// Allocator stash for cell chunks.
	chunks: storage::Stash<()>,
}

impl CellChunkAlloc {
	/// Creates a new cell and chunks allocator for the given raw parts.
	///
	/// # Note
	///
	/// Do not use this directly!
	/// This is meant to be used by pDSL internals only.
	pub unsafe fn from_raw_parts(
		cells: storage::Stash<()>,
		chunks: storage::Stash<()>,
	) -> Self {
		Self{cells, chunks}
	}

	/// Returns the key to the first cell allocation.
	///
	/// # Note
	///
	/// This key is then used to determine the key for every
	/// other cell allocation using its allocation index.
	fn cells_offset_key(&self) -> Key {
		self.cells.entries_key()
	}

	/// Returns the key to the first chunk allocation.
	///
	/// # Note
	///
	/// This key is then used to determine the key for every
	/// other chunk allocation using its allocation index.
	fn chunks_offset_key(&self) -> Key {
		self.chunks.entries_key()
	}

	/// Allocates a new storage region that fits for a single cell.
	fn alloc_cell(&mut self) -> Key {
		let index = self.cells.put(());
		self.cell_index_to_key(index)
	}

	/// Allocates a new storage region that fits for a whole chunk.
	fn alloc_chunk(&mut self) -> Key {
		let index = self.chunks.put(());
		self.chunk_index_to_key(index)
	}

	/// Deallocates a storage region fit for a single cell.
	fn dealloc_cell(&mut self, key: Key) {
		let index = self.key_to_cell_index(key);
		self.cells.take(index)
			.expect(
				"[pdsl_core::CellChunkAlloc::dealloc_cell] Error: \
				 key was not allocated by the allocator"
			)
	}

	/// Deallocates a storage region fit for a whole chunk.
	fn dealloc_chunk(&mut self, key: Key) {
		let index = self.key_to_chunk_index(key);
		self.chunks.take(index)
			.expect(
				"[pdsl_core::CellChunkAlloc::dealloc_chunk] Error: \
				 key was not allocated by the allocator"
			)
	}

	/// Converts cell indices to keys.
	///
	/// The reverse of `key_to_cell_index`.
	fn cell_index_to_key(&self, index: u32) -> Key {
		Key::with_offset(self.cells_offset_key(), index)
	}

	/// Converts keys to cell indices.
	///
	/// The reverse of `cell_index_to_key`.
	fn key_to_cell_index(&self, key: Key) -> u32 {
		let mut cell_offset = self.cells_offset_key();
		byte_utils::negate_bytes(cell_offset.as_bytes_mut());
		let mut res = key;
		byte_utils::bytes_add_bytes(res.as_bytes_mut(), cell_offset.as_bytes());
		debug_assert!(
			res.as_bytes()[0..28].into_iter().all(|&byte| byte == 0x0)
		);
		let index = byte_utils::bytes4_to_u32(
			byte_utils::slice4_as_array4(&res.as_bytes()[28..32])
				.unwrap()
		);
		index
	}

	/// Converts chunk indices to keys.
	///
	/// The reverse of `key_to_chunk_index`.
	fn chunk_index_to_key(&self, index: u32) -> Key {
		Key::with_chunk_offset(self.chunks_offset_key(), index)
	}

	/// Converts keys to chunk indices.
	///
	/// The reverse of `chunk_index_to_key`.
	fn key_to_chunk_index(&self, key: Key) -> u32 {
		let mut chunk_offset = self.chunks_offset_key();
		byte_utils::negate_bytes(chunk_offset.as_bytes_mut());
		let mut res = key;
		byte_utils::bytes_add_bytes(res.as_bytes_mut(), chunk_offset.as_bytes());
		debug_assert!(
			res.as_bytes()[0..24].into_iter().all(|&byte| byte == 0x0)
		);
		let index = byte_utils::bytes8_to_u64(
			byte_utils::slice8_as_array8(&res.as_bytes()[24..32])
				.unwrap()
		);
		(index >> 32) as u32
	}
}

impl Allocator for CellChunkAlloc {
	fn alloc(&mut self, size: u32) -> Key {
		debug_assert!(size != 0);
		if size <= 1 {
			self.alloc_cell()
		} else {
			self.alloc_chunk()
		}
	}

	fn dealloc(&mut self, key: Key) {
		// This assumes that the given key was previously
		// generated by the associated call to `Allocator::alloc`
		// of this same allocator implementor.
		assert!(key >= self.cells_offset_key());
		// This condition requires cells offset key
		// to be always smaller than chunks offset key.
		//
		// This must either be an invariant or we need
		// another more safe condition in the future.
		if key < self.chunks_offset_key() {
			// The key was allocated as a cell
			self.dealloc_cell(key)
		} else {
			// The key was allocated as a chunk
			self.dealloc_chunk(key)
		}
	}
}

#[cfg(all(test, feature = "test-env"))]
mod tests {
	use super::*;

	#[test]
	fn simple() {
		use crate::storage;

		let cells_next_vacant = Key(
			[
				0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
				0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
				0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
				0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
			]
		);
		let cells_len = Key::with_offset(cells_next_vacant, 1);
		let cells_entries = Key::with_offset(cells_len, u32::max_value());
		let chunks_next_vacant = Key(
			[
				0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
				0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
				0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01,
				0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
			]
		);
		let chunks_len = Key::with_offset(chunks_next_vacant, 1);
		let chunks_entries = Key::with_offset(chunks_len, u32::max_value());
		let mut alloc = unsafe {
			CellChunkAlloc::from_raw_parts(
				storage::Stash::new_unchecked(
					cells_next_vacant,
					cells_len,
					cells_entries,
				),
				storage::Stash::new_unchecked(
					chunks_next_vacant,
					chunks_len,
					chunks_entries,
				),
			)
		};

		let mut cell_allocs = [Key([0; 32]); 5];
		let mut chunk_allocs = [Key([0; 32]); 5];

		// Cell allocations
		for i in 0..5 {
			cell_allocs[i] = alloc.alloc(1);
			assert_eq!(cell_allocs[i], Key::with_offset(cells_entries, i as u32));
		}

		// Chunk allocations
		let alloc_sizes = &[10, u32::max_value(), 1337, 2, 9999_9999];
		for (i, &size) in alloc_sizes.into_iter().enumerate() {
			chunk_allocs[i] = alloc.alloc(size);
			assert_eq!(chunk_allocs[i], Key::with_chunk_offset(chunks_entries, i as u32));
		}

		// Deallocate first cell again
		alloc.dealloc(cell_allocs[0]);
		// Now the next cell allocation will take the first allocation cell again
		assert_eq!(alloc.alloc(1), cell_allocs[0]);

		// Deallocate 2nd and 4th allocations in reverse order
		alloc.dealloc(cell_allocs[3]);
		alloc.dealloc(cell_allocs[1]);
		assert_eq!(alloc.alloc(1), cell_allocs[1]);
		assert_eq!(alloc.alloc(1), cell_allocs[3]);

		// Deallocate first chunk again
		alloc.dealloc(chunk_allocs[0]);
		// Now the next chunk allocation will take the first allocation cell again
		assert_eq!(alloc.alloc(u32::max_value()), chunk_allocs[0]);

		// Deallocate 2nd and 4th allocations in reverse order
		alloc.dealloc(chunk_allocs[3]);
		alloc.dealloc(chunk_allocs[1]);
		assert_eq!(alloc.alloc(u32::max_value()), chunk_allocs[1]);
		assert_eq!(alloc.alloc(u32::max_value()), chunk_allocs[3]);
	}
}
